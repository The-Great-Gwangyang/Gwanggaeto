### 2장 맵리듀스
 + 데이터 처리를 위한 프로그래밍 모델로 다양한 언어(자바, 루비, 파이썬 등)으로 작성 가능
 + 직접 프로그래밍이 아닌 개념이해를 위해 학습하는 거라서... 프로그래밍 관련된 부분은 생략
 
#### 2.1 기상 데이터셋
+ 기상 데이터셋을 이용해 프로그램 작성 부분

#### 2.2 유닉스 도구로 데이터 분석하기
+ 처리 속도 향상을 위해 프로그램 각 부분을 병렬로 수행 필요
+ 이론적으로는 한대의 머신의 모든 하드웨어 스레드를 활용해 각 파일을 서로 다른 프로세스에 할당하여 처리하면 되지만 몇가지 문제점 존재
  1. 일을 동일 크기로 나누는 것은 쉽고 명확하지 않아서, 결국 가장 긴 파일을 처리하는 프로세스 처리시간에 의해 결정됨
   <br>→ 전체 입력 파일을 고정길이의 데이터 청크로 나눠 각 청크를 한 프로세스에 할당
  2. 독립적인 프로세스의 결과를 모두 합치는데 더 많은 처리가 필요할 수 있음
  3. 단일 머신의 처리 능력은 여전히 한계 존재
+ 병렬 처리는 쉬워보이지만 실제론 매우 복잡 → 이런 이슈 해결 위해서 하둡같은 프레임워크 

#### 2.3 하둡으로 데이터 분석하기
+ 맵리듀스 작업 : 맵 단계 + 리듀스 단계
  - 각 단계는 입력과 출력으로 키-값의 쌍을 가지며, 그 타입은 프로그래머가 선택

+ 맵 단계의 입력
  - 데이터셋의 각 행의 타입을 텍스트로 인식하는 텍스트 입력 포맷 선택
  - 값은 각 행(문자열), 키는 파일의 시작부에서 각 행이 시작되는 지점까지의 오프셋 (여기서 키는 의미없으므로 무시 가능)
  - 잘못된 데이터를 걸러주는 작업은 맵 함수에서 걸러주는게 Good
  - 맵리듀스의 흐름
  1. 데이터 입력
      > 006701199099991950051574005...9999N9+00001+999999
      > 004301199099991950051572004...9999N9+00221+999999
      > 006701199099991950051578045...9999N9-00111+999999
      > 006701199099991950051573005...9999N9+00781+999999
      
  2. 입력 : 각 행은 키-값 쌍으로 변환되어 맵 함수의 입력

      > (0,00670119909999<span style="color:orange">1950</span>051574005...9999N9<span style="color:orange">+0000</span>1+999999)
      > (58,00430119909999<span style="color:orange">1950</span>051572004...9999N9<span style="color:orange">+0022</span>1+999999)
      > (106,00670119909999<span style="color:orange">1949</span>051578045...9999N9<span style="color:orange">-0011</span>1+999999)
      > (318,00670119909999<span style="color:orange">1949</span>051573005...9999N9<span style="color:orange">+0078</span>1+999999)
    
  3. 맵 : 원하는 정보를 추출하여 내보냄 (맨 앞의 키는 각 행의 파일 오프셋으로, 맵 함수는 그냥 무시)
      > (1950,0)<br>
      > (1950,22)<br>
      > (1949,-11)<br>
      > (1949,78)

  4. 셔플 : 맵 함수 출력이 리듀스 함수의 입력으로 보내짐, 이 과정에서 키-값 쌍은 키를 기준으로 정렬되고 그룹화됨
      > (1949,[-11,78])<br>
      > (1950,[0,22])

  5. 리듀스 : 리듀스 전체를 반복해 원하는 값 추출(여기서는 연도별 최고 온도값)
      > (1949,75)<br>
      > (1950,22)

+ 자바 맵리듀스는 생락~~

#### 2.4 분산형으로 확장하기
+ 데이터 흐름
  - 맵리듀스 잡(job) : 클라이언트가 수행하는 작업의 기본 단위
    - 입력 데이터, 맵 리듀스 프로그램, 설정 정보로 구성
    - 하둡은 잡을 맵 태스크(map task)와 리듀스 태스크(reduce task)로 나누어 실행
    - 각 태스크는 YARN을 이용해 스케줄링되고 클러스터의 여러 노드에서 실행
    - 특정 노드의 태스크 하나가 실패하면 자동으로 다른 노드 재할당되어 실행
    1. 맵 태스크
       - 하둡은 맵 리듀스 잡의 입력을 입력 스플릿이라 부르는 고정 조각으로 분리, 각 스플릿마다 한 맵 태스크 생성, 스플릿의 각 레코드를 사용자 정의 맵 함수로 처리
         * 전체 입력을 통체로 처리하는 것보단 스플릿으로 분리해 처리하는게 속도 Good
         * But 스플릿 너무 작으면 스플릿 관리와 맵 태스크 생성을 위한 오버헤드로 실행시간 증가
       - 데이터 지역성 최적화 : 하둡은 HDFS 내 입력 데이터가 있는 노드에서 맵 태스크 실행시 가장 빠르게 작동
        <br>→ 클러스터의 중요 공유 자원인 네트워크 대역폭을 사용하지 않는 방법
        <br>→ But 맵 태스크의 입력 스플릿에 해당하는 HDFS 블록 복제본이 저장된 3개의 노드 모두 다른 맵 태스크를 실행해 여유가 없는 상황 발생할 수 있음(데이터 지역성을 위한 가용 슬롯이 없는 상황)
        <br>→ 잡 스케줄러는 블록 복제본이 저장된 동일 랙에 속한 다른 노드에서 가용 맵 슬롯 찾고, 이때 랙 간 네트워크 전송이 불가피하게 발생
       - 최적 스플릿 크기는 HDFS 블록 크기와 같아야 함
       <br>→ 그 크기가 단일 노드에 저장된다고 확신가능한 가장 큰 입력 크기라서 
        <br>→ 한 스플릿이 두 블록에 걸쳐있을때, 두 블록 모두 저장하는 HDFS노드는 존재할 가능성이 낮음 → 스플릿 일부 데이터를 네트워크를 통해 맵 태스크가 실행되는 다른 노드로 전송해야함 → 맵 태스크 전체가 로컬 데이터만 이용할때보다 느려짐
       - 맵 태스크 결과는 HDFS가 아닌 로컬에 저장됨 : 맵 결과는 리듀스가 최종 결과를 생성하기 위한 중간 결과물이고, 잡이 완료되면 그냥 버려지기 때문
       <br>→ 리듀스 태스크로 결과를 모두 보내기 전 맵 태스크가 실패하면 하둡은 자동으로 해당 맵 태스크를 다른 노드에 할당해 맵 출력을 다시 생성
    2. 리듀스 태스크
       - 일반적으로 모든 매퍼의 출력 결과를 입력으로 받기 때문에 지역성의 장점 없음
       - 일반적으로 리듀스 결과는 안정성을 위해 HDFS에 저장
       - 리듀스 출력에 대한 HDFS 블록의 첫번째 복제본은 로컬 노드에 저장, 나머지 복제본은 외부 랙에 저장
       - 리듀스 태스크 수는 입력 크기와 상관없이 독립 크기로 지정 가능
       - 리듀스가 여럿이면 리듀스 수만큼 파티션 생성하고 맵 결과를 각 파티션에 분배
       - 각 파티션에는 여러 키가 존재하지만 개별 키에 속한 모든 레코드는 여러 파티션 중 한곳에만 배치
       - 리듀스 수를 선택하는 것은 잡의 실행시간에 매우 큰영향이 있어 튜닝 필요
       - 리듀스 태스크가 아예 없는 경우는, 셔플이 필요없고 모든 처리 과정을 완전히 병럴로 처리하는 경우에 적합
       > 단일 리듀스 태스크의 맵리듀스 데이터 흐름
       <img src="/hadoop/woo/하둡기초/reduce1.png" width="450px" height="300px"  alt="단일리듀스"></img><br/>
       

  - 


      * 
  - 



출처) 톰 화이트,『하둡 완벽 가이드 데이터의 숨겨진 힘을 끌어내는 최고의 클라우드 컴퓨팅 기술』, 장형석, 장정호, 임상배, 김훈동 옮김, 한빛미디어(2017), p57~ㅇㅇㅇ
